{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a411e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#virtually move to parent directory\n",
    "os.chdir(\"CLIP-dissect\")\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import utils\n",
    "import data_utils\n",
    "import similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae756db",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = 'CLIP_layer3'\n",
    "\n",
    "settings = {\n",
    "            'CLIP_layer3': {\"target_name\":'resnet50', \"target_layer\": 'layer3', \"neurons_to_display\": \"CLIP-Dissect\"}\n",
    "           }\n",
    "\n",
    "target_name = settings[figure][\"target_name\"]\n",
    "target_layer = settings[figure][\"target_layer\"]\n",
    "neurons_to_display = settings[figure][\"neurons_to_display\"]\n",
    "\n",
    "clip_name = 'ViT-B/16'\n",
    "d_probe = 'broden'\n",
    "concept_set = 'data/broden_labels_clean.txt'\n",
    "batch_size = 200\n",
    "device = 'cuda'\n",
    "pool_mode = 'avg'\n",
    "\n",
    "save_dir = 'saved_activations'\n",
    "similarity_fn = similarity.soft_wpmi\n",
    "\n",
    "utils.save_activations(clip_name = clip_name, \n",
    "                       target_name = target_name, target_layers = [target_layer], \n",
    "                       d_probe = d_probe, concept_set = concept_set, batch_size = batch_size, \n",
    "                       device = device, pool_mode=pool_mode, save_dir = save_dir)\n",
    "\n",
    "\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                  target_layer = target_layer, d_probe = d_probe,\n",
    "                                  concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                  save_dir = save_dir)\n",
    "\n",
    "target_save_name, clip_save_name, text_save_name = save_names\n",
    "\n",
    "similarities, target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name, \n",
    "                                                             text_save_name, similarity_fn, device=device)\n",
    "\n",
    "with open(concept_set, 'r') as f: \n",
    "    words = (f.read()).split('\\n')\n",
    "\n",
    "pil_data = data_utils.get_data(d_probe)\n",
    "\n",
    "top_vals, top_ids = torch.topk(target_feats, k=5, dim=0)\n",
    "\n",
    "name_conversion = {'resnet50':'resnet50_imagenet', 'resnet18_places':'resnet18_places365'}\n",
    "ood_names = {'resnet50':'p', 'resnet18_places': 'i'}\n",
    "\n",
    "# Load Network Dissection results\n",
    "netdissect_res = pd.read_csv('data/NetDissect_results/{}_{}.csv'.format(name_conversion[target_name],\n",
    "                                                                       target_layer))\n",
    "nd_ious = netdissect_res['score'].values\n",
    "nd_labels = netdissect_res['label'].values\n",
    "\n",
    "#Load MILAN results\n",
    "milan_base = pd.read_csv('data/MILAN_results/m_base_{}.csv'.format(name_conversion[target_name]))\n",
    "if target_name == 'resnet50':\n",
    "    milan_ood = pd.read_csv('data/MILAN_results/m_places365_{}.csv'.format(name_conversion[target_name]))\n",
    "elif target_name == 'resnet18_places':\n",
    "    milan_ood = pd.read_csv('data/MILAN_results/m_imagenet_{}.csv'.format(name_conversion[target_name]))\n",
    "    \n",
    "milan_base = milan_base[milan_base['layer']==target_layer]\n",
    "milan_base = milan_base.sort_values(by=['unit'])\n",
    "milan_base = list(milan_base['description'])\n",
    "\n",
    "milan_ood = milan_ood[milan_ood['layer']==target_layer]\n",
    "milan_ood = milan_ood.sort_values(by=['unit'])\n",
    "milan_ood = list(milan_ood['description'])\n",
    "\n",
    "# Calculate which neurons to show\n",
    "if type(neurons_to_display)==list:\n",
    "    ids_to_check = neurons_to_display\n",
    "if neurons_to_display == \"CLIP-Dissect\":\n",
    "    ids_to_check = torch.sort(torch.max(similarities, dim=1)[0], descending=True)[1][0:100]\n",
    "elif neurons_to_display == \"NetDissect\":\n",
    "    ids_to_check = torch.sort(torch.tensor(nd_ious), descending=True)[1][0:100]\n",
    "\n",
    "    \n",
    "#plot figures\n",
    "font_size=14\n",
    "font = {'size'   : font_size}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "fig = plt.figure(figsize=[10, len(ids_to_check)*2.2])\n",
    "subfigs = fig.subfigures(nrows=len(ids_to_check), ncols=1)\n",
    "for j, orig_id in enumerate(ids_to_check):\n",
    "    vals, ids = torch.topk(similarities[orig_id], k=5, largest=True)\n",
    "        \n",
    "    subfig = subfigs[j]\n",
    "    subfig.text(0.13, 0.96, \"Neuron {}:\".format(int(orig_id)), size=font_size)\n",
    "    subfig.text(0.27, 0.96, \"CLIP-Dissect:\", size=font_size)\n",
    "    subfig.text(0.4, 0.96, words[int(ids[0])], size=font_size)\n",
    "    subfig.text(0.53 ,0.96, \"NetDissect:\", size=font_size)\n",
    "    subfig.text(0.65 ,0.96, nd_labels[orig_id], size=font_size)\n",
    "    \n",
    "    subfig.text(0.13, 0.85, \"MILAN(b):\", size=font_size)\n",
    "    subfig.text(0.24, 0.85, milan_base[orig_id], size=font_size)\n",
    "    \n",
    "    subfig.text(0.53, 0.85, \"MILAN({}):\".format(ood_names[target_name]), size=font_size)\n",
    "    subfig.text(0.63, 0.85, milan_ood[orig_id], size=font_size)\n",
    "    axs = subfig.subplots(nrows=1, ncols=5)\n",
    "    for i, top_id in enumerate(top_ids[:, orig_id]):\n",
    "        im, label = pil_data[top_id]\n",
    "        im = im.resize([375,375])\n",
    "        axs[i].imshow(im)\n",
    "        axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dea555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_data = []\n",
    "\n",
    "# Iterate through neurons and gather data\n",
    "for j, orig_id in enumerate(ids_to_check):\n",
    "    vals, ids = torch.topk(similarities[orig_id], k=5, largest=True)\n",
    "\n",
    "    # Gather information for each neuron\n",
    "    neuron_info = {\n",
    "        'Neuron_Number': int(orig_id),\n",
    "        'CLIP-Dissect': words[int(ids[0])],\n",
    "        'NetDissect': nd_labels[orig_id],\n",
    "        'MILAN(b)': milan_base[orig_id],\n",
    "        'MILAN({})'.format(ood_names[target_name]): milan_ood[orig_id]\n",
    "    }\n",
    "\n",
    "    neuron_data.append(neuron_info)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(neuron_data)\n",
    "\n",
    "# Save DataFrame to Excel with encoding specified when reading the CSV\n",
    "excel_file_path = 'neuron_data_layer3_label.xlsx'\n",
    "df.to_excel(excel_file_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f'Data saved to {excel_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
